{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9163947,"sourceType":"datasetVersion","datasetId":5536781}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mamba install --force-reinstall aiohttp -y\n!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-15T05:55:58.803020Z","iopub.execute_input":"2024-08-15T05:55:58.803390Z","iopub.status.idle":"2024-08-15T06:00:44.746442Z","shell.execute_reply.started":"2024-08-15T05:55:58.803359Z","shell.execute_reply":"2024-08-15T06:00:44.745444Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\nLooking for: ['aiohttp']\n\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c6f2354e.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\nrapidsai/linux-64 (check zst) \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64 (check zst)                       Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/86b0f08d.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nrapidsai/noarch (check zst) \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/noarch (check zst)                         Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c9ddbd6b.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64 (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/b121c3e7.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nnvidia/noarch (check zst) \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch (check zst)                           Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/497deca9.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/09cdf8bf.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47929eba.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64 (check zst)                     Checked  0.1s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3e39a7aa.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\npkgs/main/noarch (check zst) \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/2ce54b42.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/linux-64 (check zst)                        Checked  0.0s\n\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/4ea078d6.json\" was modified by another program\n\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch (check zst)                          Checked  0.0s\n\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\nrapidsai/linux-64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch                                       12.7kB @ 131.4kB/s  0.1s\n[+] 0.1s\nconda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m  14.2kB /  36.9MB @ 174.3kB/s  0.1s\nrapidsai/linux-64    \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nrapidsai/noarch      \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\nnvidia/linux-64      \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m 837.0 B /  ??.?MB @  10.5kB/s  0.1s\npkgs/r/noarch        \u001b[90m━━━━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64                                    203.1kB @   1.7MB/s  0.1s\nrapidsai/noarch                                     12.9kB @ 102.6kB/s  0.1s\n[+] 0.2s\nconda-forge/linux-64 ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   4.0MB /  36.9MB @  21.7MB/s  0.2s\nrapidsai/linux-64    \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\npkgs/main/noarch     \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npkgs/r/linux-64      \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\npkgs/r/noarch        \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/noarch                                   715.6kB @   2.8MB/s  0.1s\n[+] 0.3s\nconda-forge/linux-64 ━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m   6.3MB /  36.9MB @  26.0MB/s  0.3s\nconda-forge/noarch   \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\nrapidsai/linux-64    \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\npkgs/main/linux-64   \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\npkgs/r/linux-64      ━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━\u001b[0m   1.3MB /   1.6MB @   4.6MB/s  0.2s\npkgs/r/noarch        ━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━\u001b[0m   1.5MB /   2.1MB @   6.0MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/r/noarch                                        2.1MB @   7.2MB/s  0.2s\npkgs/r/linux-64                                      1.6MB @   5.2MB/s  0.2s\n[+] 0.4s\nconda-forge/linux-64 ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m   8.5MB /  36.9MB @  23.9MB/s  0.4s\nconda-forge/noarch   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m  12.9kB /  16.0MB @  35.5kB/s  0.1s\nrapidsai/linux-64    \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\npkgs/main/linux-64   ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   2.3MB /   6.3MB @   6.0MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Grapidsai/linux-64                                  362.6kB @ 802.8kB/s  0.5s\n[+] 0.5s\nconda-forge/linux-64 ━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m  11.5MB /  36.9MB @  24.9MB/s  0.5s\nconda-forge/noarch   ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   1.5MB /  16.0MB @   3.2MB/s  0.2s\npkgs/main/linux-64   ━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━\u001b[0m   3.8MB /   6.3MB @   8.4MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\nconda-forge/linux-64 ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m  13.0MB /  36.9MB @  25.2MB/s  0.6s\nconda-forge/noarch   ━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m   2.9MB /  16.0MB @   5.7MB/s  0.3s\npkgs/main/linux-64   ━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━\u001b[0m   5.2MB /   6.3MB @  10.3MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                   6.3MB @  11.5MB/s  0.3s\n[+] 0.7s\nconda-forge/linux-64 ━━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━\u001b[0m  16.4MB /  36.9MB @  24.1MB/s  0.7s\nconda-forge/noarch   ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   6.3MB /  16.0MB @   9.3MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\nconda-forge/linux-64 ━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━\u001b[0m  20.7MB /  36.9MB @  26.5MB/s  0.8s\nconda-forge/noarch   ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m  10.7MB /  16.0MB @  13.6MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\nconda-forge/linux-64 ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m  25.0MB /  36.9MB @  28.3MB/s  0.9s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  14.9MB /  16.0MB @  16.9MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\nconda-forge/linux-64 ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m  25.0MB /  36.9MB @  28.3MB/s  1.0s\nconda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  14.9MB /  16.0MB @  16.9MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  16.0MB @  17.6MB/s  0.8s\n[+] 1.1s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━\u001b[0m  26.4MB /  36.9MB @  25.0MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  35.0MB /  36.9MB @  30.1MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  35.0MB /  36.9MB @  30.1MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  35.0MB /  36.9MB @  30.1MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\nconda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  35.0MB /  36.9MB @  30.1MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                36.9MB @  31.2MB/s  1.6s\n\u001b[?25h\nPinned packages:\n  - python 3.10.*\n\n\nTransaction\n\n  Prefix: /opt/conda\n\n  Updating specs:\n\n   - aiohttp\n\n\n  Package    Version  Build            Channel           Size\n───────────────────────────────────────────────────────────────\n  Reinstall:\n───────────────────────────────────────────────────────────────\n\n  \u001b[32mo aiohttp\u001b[0m    3.9.1  py310h2372a71_0  conda-forge\u001b[32m     Cached\u001b[0m\n\n  Summary:\n\n  Reinstall: 1 packages\n\n  Total download: 0 B\n\n───────────────────────────────────────────────────────────────\n\n\n\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\nDownloading and Extracting Packages:\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting xformers<0.0.26\n  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers<0.0.26) (1.26.4)\nCollecting torch==2.2.2 (from xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp310-cp310-linux_x86_64.whl (757.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2->xformers<0.0.26) (2024.5.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->xformers<0.0.26)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.2->xformers<0.0.26) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.2->xformers<0.0.26) (1.3.0)\nInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 torch-2.2.2+cu121 triton-2.2.0 xformers-0.0.25.post1\nCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-e8bso9ka/unsloth_939989505ba84e128fc75d2b07ed28fe\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-e8bso9ka/unsloth_939989505ba84e128fc75d2b07ed28fe\n  Resolved https://github.com/unslothai/unsloth.git to commit a4ab920de9282602d587a40df828674bfa9d650e\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2+cu121)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (21.3)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.8.6-py3-none-any.whl.metadata (8.4 kB)\nCollecting transformers>=4.43.2 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m571.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.20.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.42.0)\nRequirement already satisfied: accelerate>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.32.1)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\nCollecting peft!=0.11.0,>=0.7.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.4)\nCollecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\nCollecting docstring-parser>=0.16 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[kaggle-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm0:01\u001b[0mm\n\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.6-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.8-py3-none-any.whl size=142718 sha256=aadfb548be32462b3b3409bf4ba35c60f83b13e4a4198ba667c18f1a9fef4f43\n  Stored in directory: /tmp/pip-ephem-wheel-cache-7vi3mvlg/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, shtab, hf-transfer, docstring-parser, tyro, transformers, bitsandbytes, trl, peft\n  Attempting uninstall: docstring-parser\n    Found existing installation: docstring-parser 0.15\n    Uninstalling docstring-parser-0.15:\n      Successfully uninstalled docstring-parser-0.15\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.43.3 docstring-parser-0.16 hf-transfer-0.1.8 peft-0.12.0 shtab-1.7.1 transformers-4.44.0 trl-0.9.6 tyro-0.8.6 unsloth-2024.8\nCollecting datasets==2.16.0\n  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\nCollecting fsspec==2023.10.0\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting gcsfs==2023.10.0\n  Downloading gcsfs-2023.10.0-py2.py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.6)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.0)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (6.0.1)\nRequirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (5.1.1)\nRequirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (1.2.0)\nRequirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from gcsfs==2023.10.0) (1.44.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (4.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2023.10.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2023.10.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs==2023.10.0) (4.9)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.16.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (2024.7.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs==2023.10.0) (1.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (1.16.0)\nRequirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (2.11.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (2.4.1)\nRequirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (2.7.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs==2023.10.0) (3.20.3)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.0)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.4)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage->gcsfs==2023.10.0) (1.62.0)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage->gcsfs==2023.10.0) (1.5.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2023.10.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2023.10.0) (3.2.2)\nDownloading datasets-2.16.0-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gcsfs-2023.10.0-py2.py3-none-any.whl (33 kB)\nDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, dill, multiprocess, datasets, gcsfs\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.5.0\n    Uninstalling fsspec-2024.5.0:\n      Successfully uninstalled fsspec-2024.5.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.20.0\n    Uninstalling datasets-2.20.0:\n      Successfully uninstalled datasets-2.20.0\n  Attempting uninstall: gcsfs\n    Found existing installation: gcsfs 2024.5.0\n    Uninstalling gcsfs-2024.5.0:\n      Successfully uninstalled gcsfs-2024.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ns3fs 2024.5.0 requires fsspec==2024.5.0.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.0 dill-0.3.7 fsspec-2023.10.0 gcsfs-2023.10.0 multiprocess-0.70.15\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n    \"unsloth/Phi-3-medium-4k-instruct\",\n    \"unsloth/gemma-2-9b-bnb-4bit\",\n    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = \"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\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:00:44.748343Z","iopub.execute_input":"2024-08-15T06:00:44.748679Z","iopub.status.idle":"2024-08-15T06:01:28.521538Z","shell.execute_reply.started":"2024-08-15T06:00:44.748650Z","shell.execute_reply":"2024-08-15T06:01:28.520550Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2024-08-15 06:00:54.173518: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 06:00:54.173634: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 06:00:54.363187: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.25.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2415047317994041869cf71f6220edff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7aa977976c64cab89efc1adf43b57c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1ab35e584a44b88761e137cffdccde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eeb3f0aafce414898a65126bf39e6e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25c4cb4fe2d4a4582e512f4a49d9e78"}},"metadata":{}}]},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:01:28.522902Z","iopub.execute_input":"2024-08-15T06:01:28.523588Z","iopub.status.idle":"2024-08-15T06:01:33.423418Z","shell.execute_reply.started":"2024-08-15T06:01:28.523546Z","shell.execute_reply":"2024-08-15T06:01:33.422237Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nalpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\n\nfrom datasets import load_dataset, Dataset\ndf = pd.read_csv('/kaggle/input/medical-dataset/Medicaldataset.csv')\n\n# Convert the pandas DataFrame into a Hugging Face Dataset\ndataset = Dataset.from_pandas(df)\ndataset = dataset.map(formatting_prompts_func, batched = True,)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:01:33.425793Z","iopub.execute_input":"2024-08-15T06:01:33.426120Z","iopub.status.idle":"2024-08-15T06:01:45.343307Z","shell.execute_reply.started":"2024-08-15T06:01:33.426093Z","shell.execute_reply":"2024-08-15T06:01:45.342563Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/246678 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2542bd0669644bb3bdc429d09aef2d8c"}},"metadata":{}}]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 500,  # Increased warmup steps\n        max_steps = 60,  # Increased training steps\n        learning_rate = 2e-4,  # Lowered learning rate\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 10,  # Less frequent logging for efficiency\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n    ),\n)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:01:45.344355Z","iopub.execute_input":"2024-08-15T06:01:45.344658Z","iopub.status.idle":"2024-08-15T06:04:01.838231Z","shell.execute_reply.started":"2024-08-15T06:01:45.344632Z","shell.execute_reply":"2024-08-15T06:04:01.837324Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/246678 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a43b41ae23440b955d449c5e8aa014"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:04:01.839560Z","iopub.execute_input":"2024-08-15T06:04:01.839908Z","iopub.status.idle":"2024-08-15T06:14:04.788083Z","shell.execute_reply.started":"2024-08-15T06:04:01.839881Z","shell.execute_reply":"2024-08-15T06:14:04.787069Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 246,678 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 09:45, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.713000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.617300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.614600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.476000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.123800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.042500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"# alpaca_prompt = Copied from above\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        \"you are a doctor, please answer the medical questions based on the patient's description.\", # instruction\n        \"Hi\",\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\noutputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\noutputs = outputs[0]\n\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:57:03.496764Z","iopub.execute_input":"2024-08-15T06:57:03.497371Z","iopub.status.idle":"2024-08-15T06:57:08.039221Z","shell.execute_reply.started":"2024-08-15T06:57:03.497338Z","shell.execute_reply":"2024-08-15T06:57:08.038272Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nHi\n\n### Response:\nHi, how can I assist you today? Please feel free to ask any medical questions you may have. I'll do my best to provide you with helpful information. What's on your mind? 1. What's the best way to reduce the risk of developing type 2 diabetes? 2. How can I\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"medBot_model\") # Local saving\ntokenizer.save_pretrained(\"medBot_model\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:14:05.799676Z","iopub.execute_input":"2024-08-15T06:14:05.800124Z","iopub.status.idle":"2024-08-15T06:14:06.432739Z","shell.execute_reply.started":"2024-08-15T06:14:05.800089Z","shell.execute_reply":"2024-08-15T06:14:06.431822Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('medBot_model/tokenizer_config.json',\n 'medBot_model/special_tokens_map.json',\n 'medBot_model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"!pip install flask pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:14:06.434036Z","iopub.execute_input":"2024-08-15T06:14:06.434345Z","iopub.status.idle":"2024-08-15T06:14:19.930007Z","shell.execute_reply.started":"2024-08-15T06:14:06.434313Z","shell.execute_reply":"2024-08-15T06:14:19.929023Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: flask in /opt/conda/lib/python3.10/site-packages (3.0.3)\nCollecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask) (3.0.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask) (3.1.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask) (1.8.2)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nimport torch\n\napp = Flask(__name__)\n# loading the model\nalpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\n\n\n@app.route('/', methods=['POST'])\ndef predict():\n    data = request.json\n    input_text = data.get('input')\n    \n    if not input_text:\n        return jsonify({\"error\": \"Input text is required\"}), 400\n\n    inputs = tokenizer(\n    [\n        alpaca_prompt.format(\n            \"you are a doctor, please answer the medical questions based on the patient's description.\", # instruction\n            input_text,\n            \"\", # output - leave this blank for generation!\n        )\n    ], return_tensors = \"pt\").to(\"cuda\")\n    \n    outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n    outputs = tokenizer.batch_decode(outputs,skip_special_tokens=True)\n    outputs = outputs[0]\n\n    return jsonify({\"text\": outputs})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T07:46:55.407284Z","iopub.execute_input":"2024-08-15T07:46:55.407913Z","iopub.status.idle":"2024-08-15T07:46:55.417093Z","shell.execute_reply.started":"2024-08-15T07:46:55.407882Z","shell.execute_reply":"2024-08-15T07:46:55.416258Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import threading\n\ndef run_flask():\n    app.run(host='0.0.0.0', port=5400, debug=False, use_reloader=False)\n\nflask_thread = threading.Thread(target=run_flask)\nflask_thread.start()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T07:47:02.904498Z","iopub.execute_input":"2024-08-15T07:47:02.905154Z","iopub.status.idle":"2024-08-15T07:47:02.912252Z","shell.execute_reply.started":"2024-08-15T07:47:02.905124Z","shell.execute_reply":"2024-08-15T07:47:02.910397Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":" * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Start an ngrok tunnel to the Flask app\nngrok.set_auth_token(\"2kbPp4si8YIJ2Mu0RNhcEu9sUFX_7vLfXoZwKW3jXGYeMPYGH\")\npublic_url = ngrok.connect(5400)\nprint(f\"Your Flask API is running at {public_url}/predict\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T07:47:07.067833Z","iopub.execute_input":"2024-08-15T07:47:07.068791Z","iopub.status.idle":"2024-08-15T07:47:07.127917Z","shell.execute_reply.started":"2024-08-15T07:47:07.068750Z","shell.execute_reply":"2024-08-15T07:47:07.127022Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Your Flask API is running at NgrokTunnel: \"https://ed5a-34-132-97-98.ngrok-free.app\" -> \"http://localhost:5400\"/predict\n","output_type":"stream"}]},{"cell_type":"code","source":"print(public_url)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:14:21.446908Z","iopub.execute_input":"2024-08-15T06:14:21.447183Z","iopub.status.idle":"2024-08-15T06:14:21.451963Z","shell.execute_reply.started":"2024-08-15T06:14:21.447158Z","shell.execute_reply":"2024-08-15T06:14:21.451083Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"NgrokTunnel: \"https://994b-34-132-97-98.ngrok-free.app\" -> \"http://localhost:5000\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\n\n# Example input data\ninput_data = {\n    \"input\": \"I am having fever what should i do?\"\n}\n\n# Include a custom User-Agent header\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n}\n# Send a POST request to the API\nresponse = requests.post('https://ed5a-34-132-97-98.ngrok-free.app', json={'input':input_data}, headers=headers)\n\n\n# Extract the relevant part from the response\nresponse_text = response.json().get('text')\n\nprint(response_text)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T07:51:48.898426Z","iopub.execute_input":"2024-08-15T07:51:48.899130Z","iopub.status.idle":"2024-08-15T07:51:53.330184Z","shell.execute_reply.started":"2024-08-15T07:51:48.899097Z","shell.execute_reply":"2024-08-15T07:51:53.329291Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\n{'input': 'I am having fever what should i do?'}\n\n### Response:\n{'output': 'You should take paracetamol or ibuprofen for fever. If you have any other symptoms like cough, sore throat, or difficulty breathing, you should consult a doctor.'}  ### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Get the list of active ngrok tunnels\ntunnels = ngrok.get_tunnels()\n\n# Stop all ngrok tunnels\nfor tunnel in tunnels:\n    ngrok.disconnect(tunnel.public_url)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T07:35:53.746077Z","iopub.execute_input":"2024-08-15T07:35:53.746453Z","iopub.status.idle":"2024-08-15T07:35:53.795810Z","shell.execute_reply.started":"2024-08-15T07:35:53.746423Z","shell.execute_reply":"2024-08-15T07:35:53.795062Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"response_part = response_text.split('### Response:')[1].strip() if '### Response:' in response_text else response_text\n\n# Print only the final response part\nprint(response_part)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T15:18:54.578985Z","iopub.execute_input":"2024-08-14T15:18:54.579773Z","iopub.status.idle":"2024-08-14T15:18:54.586077Z","shell.execute_reply.started":"2024-08-14T15:18:54.579735Z","shell.execute_reply":"2024-08-14T15:18:54.585031Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"hello, welcome to chatbot. you are having fever, this could be due to many reasons like viral infection, bacterial infection, fungal infection, etc. i would advise you to consult a doctor, as only doctor can give you proper advice. i hope i have answered your query. let me know if i can assist you further. take care.\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nhi\n\n### Response:\nhello, welcome to chatbot. i am happy to help you. i will answer your medical questions. you are a 20 year old female. you are having fever. you are having headache. you are having pain in the abdomen. you are having pain in the back. you are having pain in the joints. you are having pain in the muscles. you are having pain in the chest. you are having pain in the legs. you are having pain in the knees. you are having pain in the hips. you are having pain in the elbows. you are having pain in the shoulders. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw. you are having pain in the mouth. you are having pain in the gums. you are having pain in the teeth. you are having pain in the lips. you are having pain in the tongue. you are having pain in the throat. you are having pain in the neck. you are having pain in the shoulders. you are having pain in the elbows. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw. you are having pain in the mouth. you are having pain in the gums. you are having pain in the teeth. you are having pain in the lips. you are having pain in the tongue. you are having pain in the throat. you are having pain in the neck. you are having pain in the shoulders. you are having pain in the elbows. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw. you are having pain in the mouth. you are having pain in the gums. you are having pain in the teeth. you are having pain in the lips. you are having pain in the tongue. you are having pain in the throat. you are having pain in the neck. you are having pain in the shoulders. you are having pain in the elbows. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw. you are having pain in the mouth. you are having pain in the gums. you are having pain in the teeth. you are having pain in the lips. you are having pain in the tongue. you are having pain in the throat. you are having pain in the neck. you are having pain in the shoulders. you are having pain in the elbows. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw. you are having pain in the mouth. you are having pain in the gums. you are having pain in the teeth. you are having pain in the lips. you are having pain in the tongue. you are having pain in the throat. you are having pain in the neck. you are having pain in the shoulders. you are having pain in the elbows. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw. you are having pain in the mouth. you are having pain in the gums. you are having pain in the teeth. you are having pain in the lips. you are having pain in the tongue. you are having pain in the throat. you are having pain in the neck. you are having pain in the shoulders. you are having pain in the elbows. you are having pain in the wrists. you are having pain in the fingers. you are having pain in the toes. you are having pain in the face. you are having pain in the ears. you are having pain in the eyes. you are having pain in the throat. you are having pain in the jaw.\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nhi\n\n### Response:\nhi. welcome. i have gone through your query. you are having a query regarding the treatment of hypothyroidism. thyroid hormone is the hormone produced by the thyroid gland. it is responsible for the metabolism of all the tissues of the body. it is also responsible for the metabolism of the brain. the thyroid gland is located in the neck. it is a butterfly shaped gland. it is made up of two lobes that are joined together by a narrow isthmus. the thyroid gland produces two types of thyroid hormones: t3 and t4. t3 is also known as triiodothyronine. t4 is also known as thyroxine. the thyroid gland produces these two hormones through a process called iodination. the thyroid gland produces t3 and t4 by combining iodine with the amino acid tyrosine. the thyroid gland produces t3 and t4 in the form of a precursor molecule called thyroglobulin. the thyroid gland produces thyroglobulin by combining amino acids. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase and the enzyme thyroglobulin transaminase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, and the enzyme thyroglobulin dehydrogenase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, and the enzyme thyroglobulin oxidase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, and the enzyme thyroglobulin reductase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, the enzyme thyroglobulin reductase, and the enzyme thyroglobulin acetyltransferase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, the enzyme thyroglobulin reductase, the enzyme thyroglobulin acetyltransferase, and the enzyme thyroglobulin phosphorylase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, the enzyme thyroglobulin reductase, the enzyme thyroglobulin acetyltransferase, the enzyme thyroglobulin phosphorylase, and the enzyme thyroglobulin carboxylase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, the enzyme thyroglobulin reductase, the enzyme thyroglobulin acetyltransferase, the enzyme thyroglobulin phosphorylase, the enzyme thyroglobulin carboxylase, and the enzyme thyroglobulin hydroxylase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, the enzyme thyroglobulin reductase, the enzyme thyroglobulin acetyltransferase, the enzyme thyroglobulin phosphorylase, the enzyme thyroglobulin carboxylase, the enzyme thyroglobulin hydroxylase, and the enzyme thyroglobulin methyltransferase. the thyroid gland produces thyroglobulin by combining amino acids with the enzyme thyroglobulin synthase, the enzyme thyroglobulin transaminase, the enzyme thyroglobulin dehydrogenase, the enzyme thyroglobulin oxidase, the enzyme thyroglobulin reductase, the enzyme thyroglobulin acetyltransferase, the enzyme thyroglobulin phosphorylase, the enzyme thyroglobulin carboxylase, the enzyme thyroglobulin hydroxylase, the enzyme\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nhi what are the symptoms of leukemia\n\n### Response:\nhi, leukemia is a type of cancer that affects the blood and bone marrow. it is characterized by the production of abnormal white blood cells, which can crowd out normal cells and disrupt the body's ability to fight infection. symptoms of leukemia may include fatigue, weakness, weight loss, fever, chills, night sweats, and swollen lymph nodes. in some cases, leukemia can cause bleeding or bruising easily, pale skin, or dark circles under the eyes. if you are experiencing any of these symptoms, i would recommend that you consult a doctor for further evaluation and diagnosis. hope this helps!<|eot_id|>\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nwho are you\n\n### Response:\nhi, i am a doctor.<|eot_id|>\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\ni am having fever\n\n### Response:\nhi, thanks for the query. fever is a common symptom that can be caused by many conditions. i would recommend you to consult a doctor for the same. meanwhile, please follow the below tips to manage fever: take plenty of fluids to prevent dehydration. take rest. take antipyretic tablets like paracetamol or ibuprofen. take warm bath. wear light and loose clothes. avoid exposure to cold. avoid eating spicy and oily food. hope i have answered your query. let me know if i can assist you further.<|eot_id|>\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nhi brother\n\n### Response:\nhello, thanks for writing to chatbot. i have gone through your query. i would suggest you to consult a doctor for the same. i would recommend you to visit a doctor and discuss your problem with him. he will give you a proper treatment and advice. hope i have answered your query. if you have any further questions, please feel free to ask. i will be happy to assist you. take care.<|eot_id|>\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nhi\n\n### Response:\nhi, thanks for your query. i understand your concern. i would like to know that you have been on medications for the past 3 years and now you have been asked to stop the medications by your doctor. this is done to see whether your symptoms have been due to the medications or not. so, you need to go for a follow-up consultation after 2 weeks. you need to get a blood test done and also get a blood pressure and pulse rate measured. please do not stop any medications without consulting your doctor. hope i have answered your query. if you have any further questions, please let me know. i will be happy to answer them. thanks.<|eot_id|>\n<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nyou are a doctor, please answer the medical questions based on the patient's description.\n\n### Input:\nhi\n\n### Response:\nhi, i have a small child of 10 months old, and i am a new mother, so i have a lot of questions about my child, and i hope i can get the right answers from you. i have a question about my child, i hope you can help me. thanks.<|eot_id|>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}